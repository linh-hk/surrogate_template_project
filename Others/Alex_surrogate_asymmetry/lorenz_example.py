###################################
#### IMPORT REQUIRED LIBRARIES ####
###################################

import numpy as np
from ccm import ccm_loocv, pcorr
import matplotlib.pyplot as plt
from pyunicorn.timeseries import surrogates
from scipy.integrate import solve_ivp

###################################
#### TRY TO IMPORT LOADING BAR ####
###################################

try:
    from tqdm import tqdm
except Exception:
    print("tqdm not available. This means that you don't get the loading bar ðŸ˜”")
    def tqdm(iter, desc):
        return iter

############################
#### METHOD DEFINITIONS ####
############################

def logistic_map(n, y, interaction=0.1):
    """Logistic map driven by the signal y

    Args:
        n (int): The number of iterations to perform.
        y (array-like): The input signal driving the logistic map.
        interaction (float, optional): The interaction parameter controlling the influence of the input signal.

    Returns:
        array: The resulting array of length n containing the values generated by the logistic map.

    Docstring written (at least in part) by GPT-3 and checked by me.
    """
    x = np.zeros(n)
    x[0] = np.random.uniform(0.2, 0.8)
    for i in range(n-1):
        x[i+1] = x[i] * (3.7 - 3.7*x[i] - interaction * y[i])
    return x

def get_iaaft_surr(data, num_surr=99, n_iter=200):
	"""Get IAAFT surrogates
	Args:
	    data (numpy array): 1d array containing a time series
	    num_surr (int): number of surrogates
	    n_iter (int): number of refinement iterations

	    Returns:
	    a matrix where each column is a surrogate
	"""
	results = []
	i = 0
	while i < num_surr:
		obj = surrogates.Surrogates(original_data=data.reshape(1,-1), silence_level=2)
		surr = obj.refined_AAFT_surrogates(original_data=data.reshape(1,-1), n_iterations=n_iter, output='true_spectrum')
		surr = surr.ravel()
		if not np.isnan(np.sum(surr)):
			results.append(surr)
			i += 1
	return np.array(results).T

def ccm_pairwise(X, Y, **kwargs):
    """
    Computes cross map skill pairwise between columns of X and Y.

    Args:
        X (ndarray): Input matrix where each column represents a length-n time series.
        Y (ndarray): Input matrix where each column represents a length-n time series.
        **kwargs: Additional keyword arguments to be passed to the ccm_loocv function.

    Returns:
        ndarray: Pairwise cross map skill matrix between columns of X and Y.
                 Each element (i, j) of the matrix represents the cross map skill
                 score between the ith column of X and the jth column of Y.

    Note:
        The input matrices X and Y can have different numbers of columns.

    Docstring written (at least in part) by GPT-3 and checked by me.
    """
    _, nx = X.shape
    _, ny = Y.shape
    result = np.zeros([nx, ny])
    for ix in range(nx):
        for iy in range(ny):
            x = X[:,ix]
            y = Y[:,iy]
            data = np.concatenate([x.reshape(-1,1), y.reshape(-1,1)],axis=1)
            result[ix, iy] = ccm_loocv(data, **kwargs).score.ravel()[0]
    return result

def get_lorenz(series_length, step_size, n_burn=500, **solve_ivp_kwargs):
    """
    Generates a time series of the Lorenz system using the specified parameters.

    Args:
        series_length (int): The length of the time series to generate.
        step_size (float): The time step size between each data point in the series.
        n_burn (int, optional): The number of burn-in steps to discard from the beginning of the series.
        **solve_ivp_kwargs: Additional keyword arguments to pass to the solve_ivp function from scipy.

    Returns:
        tuple: A tuple (x, y, z) containing the generated time series for the variables x, y, and z, respectively.

    Docstring written (at least in part) by GPT-3 and checked by me.
    """

    def f(t, state):
        s = 10
        r = 28
        b = 8/3
        x, y, z = state
        xdot = s * (y - x)
        ydot = x * (r - z) - y
        zdot = x * y - b * z
        return xdot, ydot, zdot
    t = np.arange(0, step_size * (series_length + n_burn), step_size)
    init_cond = np.random.uniform(low=(-15, -20, 10), high=(15, 20, 30))
    sol = solve_ivp(f, [t[0], t[-1]], init_cond, t_eval=t, **solve_ivp_kwargs)
    x = sol.y[0, n_burn:]
    y = sol.y[1, n_burn:]
    z = sol.y[2, n_burn:]
    return x,y,z

####################
#### PARAMETERS ####
####################

np.random.seed(1)           # set random seed
nt = 200                    # time series length
nburn_lorenz = 200          # burn time for lorenz
nburn_coupled = 200         # burn time for lorenz/logistic
n_trials = 80               # number of trials for calculating TPR and FPR
n_surr = 99                 # number of surrogates
coupling_strength = 0.06    # coupling strength

############################
#### True positive rate ####
############################

pval_x = []
pval_y = []
for trial in tqdm(range(n_trials), desc="Power benchmark: Loading..."):
    # get coupled x and y time series
    _, _, y = get_lorenz(nt + nburn_coupled, 0.06, n_burn = nburn_lorenz)
    y = y / 70 + 0.15 # bring it more-or-less into the range 0â‰¤yâ‰¤1
    x = logistic_map(nt + nburn_coupled, y, interaction=coupling_strength)
    x = x[-nt:] # burn off "nburn_coupled"
    y = y[-nt:]
    # perform dependence testing
    stat = ccm_pairwise(x.reshape(-1,1),y.reshape(-1,1), embed_dim=2).ravel()[0]
    surr_x = get_iaaft_surr(x)
    surr_y = get_iaaft_surr(y)
    null_x = ccm_pairwise(surr_x, y.reshape(-1,1), embed_dim=2)
    null_y = ccm_pairwise(x.reshape(-1,1), surr_y, embed_dim=2)

    p_x = (np.sum(null_x >= stat) + 1) / (n_surr + 1)
    p_y = (np.sum(null_y >= stat) + 1) / (n_surr + 1)
    pval_x.append(p_x)
    pval_y.append(p_y)

power_nullx = np.mean(np.array(pval_x) <= 0.05)
power_nully = np.mean(np.array(pval_y) <= 0.05)
print(f'power (null x): {power_nullx}')
print(f'power (null y): {power_nully}')

#### False positive rate ####

pval_x = []
pval_y = []
for trial in tqdm (range (n_trials), desc="FPR benchmark: Loading..."):
    # get x and y time series
    _, _, y1 = get_lorenz(nt + nburn_coupled, 0.06, n_burn = nburn_lorenz)
    y1 = y1 / 70 + 0.15
    x = logistic_map(nt + nburn_coupled, y1, interaction=coupling_strength)
    x = x[-nt:]
    # throw away that y time series and get an independent y time series
    _, _, y = get_lorenz(nt + nburn_coupled, 0.06, n_burn = nburn_lorenz)
    y = y / 70 + 0.15
    y = y[-nt:]
    # perform dependence testing
    stat = ccm_pairwise(x.reshape(-1,1),y.reshape(-1,1), embed_dim=2).ravel()[0]
    surr_x = get_iaaft_surr(x)
    surr_y = get_iaaft_surr(y)
    null_x = ccm_pairwise(surr_x, y.reshape(-1,1), embed_dim=2)
    null_y = ccm_pairwise(x.reshape(-1,1), surr_y, embed_dim=2)

    p_x = (np.sum(null_x >= stat) + 1) / (n_surr + 1)
    p_y = (np.sum(null_y >= stat) + 1) / (n_surr + 1)
    pval_x.append(p_x)
    pval_y.append(p_y)

fpr_nullx = np.mean(np.array(pval_x) <= 0.05)
fpr_nully = np.mean(np.array(pval_y) <= 0.05)
print(f'FPR (null x): {fpr_nullx}')
print(f'FPR (null y): {fpr_nully}')
